
\subsection{Esempio calcolo matrice esponenziale}
Sia la seguente matrice $A$
$$
A = \begin{bmatrix}
0 & 1\\
-1 & -1
\end{bmatrix}
$$
Il polinomio caratteristico sarà
$$
p(\lambda) = \lambda^2 + \lambda +1 \left\langle \begin{aligned}
\lambda_1 &= -\frac{1}{2} + j\frac{\sqrt{3}}{2} \\
\lambda_2 &= -\frac{1}{2} -j\frac{\sqrt{3}}{2}
\end{aligned}\right.
$$
La matrice è di semplice struttura, può essere diagonalizzata per similitudine,
vanno calcolati gli autovettori
$$
(\lambda_1I-A)u_1 = 0 =\begin{pmatrix}
-\frac{1}{2} + j\frac{\sqrt{3}}{2} & -1 \\
1 & \frac{1}{2} + j\frac{\sqrt{3}}{2}
\end{pmatrix}\begin{pmatrix}
u_{11} \\ u_{12}
\end{pmatrix} = \begin{pmatrix}
0 \\0
\end{pmatrix} +j\begin{pmatrix}
0 \\ 0
\end{pmatrix}
$$
Procedendo con il calcolo, si ricorda che solo un'equazione è indipendente, si
sceglie una delle due variabili arbitrariamente, $u_{11} = 1\Rightarrow u_{12}
= -\frac{1}{2} + j\frac{\sqrt{3}}{2}$
$$
u_1 = \begin{pmatrix}
1 \\ -\frac{1}{2}+j\frac{\sqrt{3}}{2}
\end{pmatrix} = \begin{pmatrix}
1 \\ -\frac{1}{2}
\end{pmatrix} + j\begin{pmatrix}
0 \\ \frac{\sqrt{3}}{2}
\end{pmatrix} = u_a + ju_b
$$
per ricavare il vettore $u_2$ si esegue il coniugato della seguente uguaglianza
$$
Au_1 = \lambda_1u_1 \stackrel{\text{conj.}}{\longrightarrow}Au_1^* =
\lambda_1^* u_1
$$
Dato che i due autovalori sono complessi e coniugati
$$
\lambda_1^* = \lambda_2 \Rightarrow u_2 = u_1^* = u_a -ju_b
$$

Si costruisce la matrice modale $U$ con i due autovalori
$$\begin{aligned}
U &= [u_1 \quad u_2] = \begin{bmatrix}
1 & 1 \\
-\frac{1}{2}+j\frac{\sqrt{3}}{2} & -\frac{1}{2}-j\frac{\sqrt{3}}{2}
\end{bmatrix}\Rightarrow \\
e^{At} &= Ue^{\Lambda t} U^{-1} = U\begin{bmatrix}
e^{\left(-\frac{1}{2}+j\frac{\sqrt{3}}{2}\right)t} & 0\\
0 & e^{\left(-\frac{1}{2}-j\frac{\sqrt{3}}{2}\right)t}
\end{bmatrix}U^{-1}
\end{aligned}$$
Si continua lo sviluppo usando la formula di Eulero, la complessità
può essere ridotta utilizzando la matrice in forma reale.

$$
U_r = [u_a \ u_b] = \begin{bmatrix}
1 & 0 \\
-\frac{1}{2} & \frac{\sqrt{3}}{2}
\end{bmatrix} \longrightarrow \Lambda_r =\begin{bmatrix}
\alpha & \omega \\
-\omega & \alpha
\end{bmatrix}=
\begin{bmatrix}
-\frac{1}{2} & \frac{\sqrt{3}}{2}\\
-\frac{\sqrt{3}}{2} & -\frac{1}{2}
\end{bmatrix} = U_r^{-1}AU_r
$$
Sostituendo nella matrice esponenziale, con i risultati ottenuti in
\ref{eq.:esponenziale_comp_coniugata}
$$
e^{\Lambda_r t} = e^{-\frac{1}{2}t}\begin{pmatrix}
\cos \left(\frac{\sqrt{3}}{2}t\right) & \sin \left(\frac{\sqrt{3}}{2}t\right) \\
-\sin \left(\frac{\sqrt{3}}{2}t\right) & \cos \left(\frac{\sqrt{3}}{2}t\right)
\end{pmatrix}\rightarrow
e^{At} = U_r e^{\Lambda_r t} U_r^{-1}
$$

\subsection{Proprietà della matrice esponenziale}
$$
\begin{array}{>{\displaystyle}c|>{\displaystyle}c}
 e^{at}=\sum_{k=0}^{+\infty} \frac{a^kt^k}{k!} & e^{At}=\sum_{k=0}^{+\infty}
\frac{A^k t^k}{k!} \\ \hline
e^{a\cdot \text{\o{}} } = 1 & e^{A\cdot \text{\o{}}} = I\\
\frac{d}{dt} e^{at} = ae^{at} & \frac{d}{dt} e^{At} = Ae^{At} = e^{At}A\\
e^{at}\cdot e^{bt} = e^{(a+b)t} & e^{At}\cdot e^{Bt} = e^{(A+B)t}\\
\left(e^{at}\right)^{-1} = e^{-at} & \left(e^{At}\right)^{-1} = e^{-At}\\
 \hline & \text{det}\left(e^{At}\right) =
e^{\text{tr}(A)}\\
 & e^{A^Tt} = \left(e^{At}\right)^T
\end{array}
$$
Dimostrazione della derivata
$$
\frac{d}{dt} \sum_{k=0}^{+\infty} \frac{A^kt^k}{k!} =
\sum_{k=1}^{+\infty}\frac{A^kt^{k-1}}{(k-1)!} =
A\sum_{k=1}^{+\infty} \frac{A^{k-1}t^{k-1}}{(k-1)!} \stackrel{k-1=k'}{=}
A\sum_{k'=0}^{+\infty}\frac{A^{k'}t^{k'}}{k'!} = Ae^{At} = e^{At}A
$$
Solo in questo caso il prodotto tra matrici è commutativo dato che la matrice
viene moltiplicata per la sua matrice esponenziale corrispondente.

La terza proprietà (\textit{prodotto}) è vera solo se le matrici $A$ e $B$
commutano ossia \linebreak se $AB = BA$.

Dimostrazione della quarta proprietà (\textit{inversa}), sfruttando la
proprietà del prodotto, sicuramente le matrici $A$ e $-A$ commutano
$$
e^{At} \cdot e^{-At} = e^{(A-A)t} = I
$$
L'unica matrice che moltiplicata per un'altra restituisce la matrice identità è
proprio la sua inversa.

\subsection{Analisi con matrice non diagonalizzabile}
Esisterà qualche autovalore per il quale la molteplicità geometrica è
strettamente minore della molteplicità algebrica, se ciò avviene, la matrice
$A$ non è diagonalizzabile, non esiste alcuna matrice simile diagonale.

È comodo operare nel dominio di Laplace per risolvere una matrice non
diagonalizzabile, altrimenti bisogna riferirsi alla forma di
\href{https://it.wikipedia.org/wiki/Forma_canonica_di_Jordan}{Jordan},
approfondimenti
\href{https://youtu.be/mD4zrWkgy0o?list=PL6Tz-CNThN13TMpt6jGje3vbOv0rzKWS7&t=
3199}{qui} e
\href{https://youtu.be/XrnbTxP010I?list=PL6Tz-CNThN13TMpt6jGje3vbOv0rzKWS7}
{qui}.
La Jordanizzazione consiste nel costruire una matrice non diagonale $U_J$ che
mediante una trasformazione di similitudine generi la matrice $J$
$$ J = U_J^{-1}AU_J =U_J^{-1}
\begin{bmatrix}
\ddots & 0 & & & \\
 & \lambda_1 & 1 & 0 & & & &\\
 & 0 & \ddots & 1 &  & & \\
 & 0 & 0 & \lambda_1 & 0 & \\
 & & & & \lambda_2 & 1 & 0 \\
 & & & & 0& \ddots & 1 \\
 & & & & 0 & 0 & \lambda_2 & 0 &\\
 & & & & & &  & \ddots
\end{bmatrix}U_J
$$

Si costruisce una matrice formata da matrici diagonali a blocchi, si hanno
sempre gli autovalori sulla diagonale ma compaiono degli $1$ sulla
\textit{sovradiagonale}, la dimensione sarà $m_{ai}\times m_{ai}$.

Per il calcolo della matrice esponenziale invece, sapendo che l'esponenziale di
una matrice diagonale a blocchi è ancora una matrice diagonale a blocchi, si
otterrà una matrice che ha sulla diagonale le matrici esponenziali dei singoli
blocchi.
$$
e^{At} = U_Je^{Jt}U_J^{-1} = U_J\begin{bmatrix}
\ddots & \\
& e^{J_{i1} t}\\
& & e^{J_{i2} t} \\
& & & \ddots
\end{bmatrix}U_J^{-1}
$$
Il termine $e^{J_{in}t}$ è l'esponenziale $n-$esimo del \textit{miniblocco} di
Jordan, si dimostra che ha dimensione $m_{ai}$ e la seguente forma
$$
e^{J_{in} t} =e^{\lambda_i t} \begin{bmatrix}
1 & t & \frac{t^2}{2} & \frac{t^3}{3!} & \frac{t^4}{4!} \\
0 & 1 & t & \frac{t^2}{2} & \frac{t^3}{3!}  \\
0 & 0 & 1 & t & \frac{t^2}{2} \\
0 & 0 & 0 & 1 & t  \\
0 & 0 & 0 & 0 & 1
\end{bmatrix}
$$
L'analisi di questo tipo di matrici verrà ripresa con l'analisi dei sistemi nel
dominio di Laplace.

\newpage
\section{Calcolo dell'integrale generale della ISU}
Si consideri un sistema LTI nella forma ISU implicita
$$
\dot{x} = Ax + Bu
$$
Si vuole ricavare l'integrale della soluzione $x(t)$
$$
x(t) = x_h(t) + x_p(t)
$$
Si studia la soluzione dell'omogenea, assumendo che sia
$$
\dot x_h = Ax_h \rightarrow x_h(t) = e^{A(t-t_0)}\cdot c \quad t\geq t_0,\
c\in\mathbb{R}^n
$$
Per dimostrare la precedente equazione è sufficiente sostituire il risultato
ipotizzato nell'equazione di partenza e derivando si ottiene
$$
\dot{x}_h(t) = Ae^{A(t-t_0)} \cdot c = Ax_h(t)
$$
Esistono infinite soluzioni dato che la scelta del vettore $c$ costante è
arbitraria.

L'integrale \textbf{particolare} invece si risolve con la seguente ipotesi di
soluzione
$$
x_p(t) = \int_{t_0}^t e^{A(t-\tau)}Bu(\tau)d\tau =
e^{At} \int_{t_0}^t e^{-A\tau}Bu(\tau)d\tau
$$
Anche questa si basa sulla matrice esponenziale, si verifica che sia
effettivamente soluzione dell'equazione differenziale, analogamente al caso
precedente si sostituisce e si deriva il prodotto dei due termini entrambi
dipendenti dal tempo, con la nota formula $\frac{d}{dt}(AB) = A'B + AB'$
$$\begin{aligned}
\dot{x}_p(t) &= Ae^{At} \int_{t_0}^t e^{-A\tau}Bu(\tau)d\tau +
e^{At}e^{-At}Bu(t) =\\
&=A \int_{t_0}^t e^{A(t-\tau)}Bu(\tau)d\tau + Bu(t) = \\
&= Ax_p(t) + Bu
\end{aligned}$$

56:18
